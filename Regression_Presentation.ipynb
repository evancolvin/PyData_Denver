{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Cases for Linear and Logistic Regression with Scikit-Learn\n",
    "\n",
    "* **Continuous Predictors**\n",
    "    * Linear Regression \n",
    "    * Tree Regression\n",
    "* **Binary Classifiers**\n",
    "    * Logistic Regression\n",
    "    * Naive Bayes (if Time)\n",
    "    \n",
    "We'll use my good friend Scikit-Learn: http://scikit-learn.org/stable/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Variables & Linear Regression\n",
    "\n",
    "Outcomes can take on a real-value in a range between $-\\inf$ and $\\inf$. It's still good if your predictors only take on a range between certain values. \n",
    "\n",
    "Formula in the form $Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_n X_n + \\epsilon$, where $\\epsilon$ is the error term. Includes things we forgot to include, things we can't measure, measurement error, etc. \n",
    "\n",
    "Each $\\beta$ is the value we expect per a one-unit change in the corresponding $X$. So if $\\beta_3 = 4.3$, we expect $Y$ to go up $4.3$ units whenever $X_3$ increase by one-unit. \n",
    "\n",
    "Fit in the new data into the formula, multiply by the $\\beta$'s and that's your prediction\n",
    "\n",
    "We use the form $\\hat{Y} = \\hat{\\beta_0} + \\hat{\\beta_1} X_1 + \\hat{\\beta_2} X_2 + ... + \\hat{\\beta_n} X_n$ where the 'hats' show those are the calculated values, nor the error. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the X's \n",
    "\n",
    "We use a series of matrix operations to calculate the values of the $\\beta$'s. \n",
    "\n",
    "$$ X = \n",
    "\\begin{matrix}\n",
    "1 & X_{1,1} & X_{1,2} & X_{1,3} &...& X_{1,n}\\\\\n",
    "1 & X_{2,1} & X_{2,2} & X_{2,3} &...& X_{2,n}\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots& \\ddots & \\vdots \\\\\n",
    "1 & X_{m,1} & X_{m,2} & X_{m,3} &...& X_{m,n}\n",
    "\\end{matrix}$$\n",
    "\n",
    "Where the $X$'s are our data points. \n",
    "\n",
    "We do some matrix operations: $(X^TX)^{-1}X^T y = \\hat{\\underline{\\beta}}$ to generate our coefficients. Then we use the formula $\\hat{Y} = \\hat{\\underline{\\beta}}X$ to get our predictions. \n",
    "\n",
    "We don't actually do this. Matrix operations are insanely expensive for computers to perform. Matrix multiplication is $O(n^{2.373})$ under the fastest matrix multiplication algorithms. So computers use a gradient descent algorithm that tries to minimize the squared distance between the predicted outcomes and the actual outcomes.\n",
    "\n",
    "We define the residuals, $r$, as $r = \\hat{Y} - Y$. We want those residuals to look like random noise, and ideally normally distributed with mean 0. \n",
    "<img src = \"good_resids1.png\">\n",
    "\n",
    "Residuals with a pattern suggest we missed something \n",
    "<img src = \"bad_resids.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Look at Some Data\n",
    "\n",
    "We'll use the Boston Housing Data for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "boston = pd.read_csv(\"/Users/evancolvin/dropbox/projects/PyData/Boston.csv\", sep = '\\t')\n",
    "cancer = pd.read_csv(\"/Users/evancolvin/dropbox/projects/PyData/cancer.csv\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.02985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.430</td>\n",
       "      <td>58.7</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.12</td>\n",
       "      <td>5.21</td>\n",
       "      <td>28.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.08829</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.012</td>\n",
       "      <td>66.6</td>\n",
       "      <td>5.5605</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>395.60</td>\n",
       "      <td>12.43</td>\n",
       "      <td>22.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.14455</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.172</td>\n",
       "      <td>96.1</td>\n",
       "      <td>5.9505</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>19.15</td>\n",
       "      <td>27.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.21124</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>5.631</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0821</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.63</td>\n",
       "      <td>29.93</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.17004</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.004</td>\n",
       "      <td>85.9</td>\n",
       "      <td>6.5921</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.71</td>\n",
       "      <td>17.10</td>\n",
       "      <td>18.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.22489</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.377</td>\n",
       "      <td>94.3</td>\n",
       "      <td>6.3467</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>392.52</td>\n",
       "      <td>20.45</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.11747</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.009</td>\n",
       "      <td>82.9</td>\n",
       "      <td>6.2267</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>13.27</td>\n",
       "      <td>18.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.09378</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>5.889</td>\n",
       "      <td>39.0</td>\n",
       "      <td>5.4509</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>390.50</td>\n",
       "      <td>15.71</td>\n",
       "      <td>21.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.62976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.949</td>\n",
       "      <td>61.8</td>\n",
       "      <td>4.7075</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>8.26</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.63796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.096</td>\n",
       "      <td>84.5</td>\n",
       "      <td>4.4619</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>21.0</td>\n",
       "      <td>380.02</td>\n",
       "      <td>10.26</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.62739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.834</td>\n",
       "      <td>56.5</td>\n",
       "      <td>4.4986</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>21.0</td>\n",
       "      <td>395.62</td>\n",
       "      <td>8.47</td>\n",
       "      <td>19.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.05393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.935</td>\n",
       "      <td>29.3</td>\n",
       "      <td>4.4986</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>21.0</td>\n",
       "      <td>386.85</td>\n",
       "      <td>6.58</td>\n",
       "      <td>23.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.78420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.990</td>\n",
       "      <td>81.7</td>\n",
       "      <td>4.2579</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>21.0</td>\n",
       "      <td>386.75</td>\n",
       "      <td>14.67</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.80271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.456</td>\n",
       "      <td>36.6</td>\n",
       "      <td>3.7965</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>21.0</td>\n",
       "      <td>288.99</td>\n",
       "      <td>11.69</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.72580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.727</td>\n",
       "      <td>69.5</td>\n",
       "      <td>3.7965</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>21.0</td>\n",
       "      <td>390.95</td>\n",
       "      <td>11.28</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       crim    zn  indus  chas    nox     rm    age     dis  rad  tax  \\\n",
       "1   0.00632  18.0   2.31     0  0.538  6.575   65.2  4.0900    1  296   \n",
       "2   0.02731   0.0   7.07     0  0.469  6.421   78.9  4.9671    2  242   \n",
       "3   0.02729   0.0   7.07     0  0.469  7.185   61.1  4.9671    2  242   \n",
       "4   0.03237   0.0   2.18     0  0.458  6.998   45.8  6.0622    3  222   \n",
       "5   0.06905   0.0   2.18     0  0.458  7.147   54.2  6.0622    3  222   \n",
       "6   0.02985   0.0   2.18     0  0.458  6.430   58.7  6.0622    3  222   \n",
       "7   0.08829  12.5   7.87     0  0.524  6.012   66.6  5.5605    5  311   \n",
       "8   0.14455  12.5   7.87     0  0.524  6.172   96.1  5.9505    5  311   \n",
       "9   0.21124  12.5   7.87     0  0.524  5.631  100.0  6.0821    5  311   \n",
       "10  0.17004  12.5   7.87     0  0.524  6.004   85.9  6.5921    5  311   \n",
       "11  0.22489  12.5   7.87     0  0.524  6.377   94.3  6.3467    5  311   \n",
       "12  0.11747  12.5   7.87     0  0.524  6.009   82.9  6.2267    5  311   \n",
       "13  0.09378  12.5   7.87     0  0.524  5.889   39.0  5.4509    5  311   \n",
       "14  0.62976   0.0   8.14     0  0.538  5.949   61.8  4.7075    4  307   \n",
       "15  0.63796   0.0   8.14     0  0.538  6.096   84.5  4.4619    4  307   \n",
       "16  0.62739   0.0   8.14     0  0.538  5.834   56.5  4.4986    4  307   \n",
       "17  1.05393   0.0   8.14     0  0.538  5.935   29.3  4.4986    4  307   \n",
       "18  0.78420   0.0   8.14     0  0.538  5.990   81.7  4.2579    4  307   \n",
       "19  0.80271   0.0   8.14     0  0.538  5.456   36.6  3.7965    4  307   \n",
       "20  0.72580   0.0   8.14     0  0.538  5.727   69.5  3.7965    4  307   \n",
       "\n",
       "    ptratio   black  lstat  medv  \n",
       "1      15.3  396.90   4.98  24.0  \n",
       "2      17.8  396.90   9.14  21.6  \n",
       "3      17.8  392.83   4.03  34.7  \n",
       "4      18.7  394.63   2.94  33.4  \n",
       "5      18.7  396.90   5.33  36.2  \n",
       "6      18.7  394.12   5.21  28.7  \n",
       "7      15.2  395.60  12.43  22.9  \n",
       "8      15.2  396.90  19.15  27.1  \n",
       "9      15.2  386.63  29.93  16.5  \n",
       "10     15.2  386.71  17.10  18.9  \n",
       "11     15.2  392.52  20.45  15.0  \n",
       "12     15.2  396.90  13.27  18.9  \n",
       "13     15.2  390.50  15.71  21.7  \n",
       "14     21.0  396.90   8.26  20.4  \n",
       "15     21.0  380.02  10.26  18.2  \n",
       "16     21.0  395.62   8.47  19.9  \n",
       "17     21.0  386.85   6.58  23.1  \n",
       "18     21.0  386.75  14.67  17.5  \n",
       "19     21.0  288.99  11.69  20.2  \n",
       "20     21.0  390.95  11.28  18.2  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "* **crim:** Per Capita Crime per Town\n",
    "* **zn:** proportion of residential land zoned for lots over 25,000 sq.ft\n",
    "* **indus:** proportion of non-retail business acres per town\n",
    "* **chas:** Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).\n",
    "* **nox:** nitrogen oxides concentration (parts per 10 million)\n",
    "* **rm:** average number of rooms per dwelling\n",
    "* **age:** proportion of owner-occupied units built prior to 1940\n",
    "* **dis:** weighted mean of distances to five Boston employment centres\n",
    "* **rad:** index of accessibility to radial highways\n",
    "* **tax:** full-value property-tax rate per <span>$</span>10,000\n",
    "* **ptratio:** pupil-teacher ratio by town\n",
    "* **black:** 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "* **lstat:** lower status of the population (percent)\n",
    "* **medv:** median value of owner-occupied homes in 1000s. <--What we Want to Predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.677082</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             crim          zn       indus        chas         nox          rm  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677082   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              age         dis         rad         tax     ptratio       black  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            lstat        medv  \n",
       "count  506.000000  506.000000  \n",
       "mean    12.653063   22.532806  \n",
       "std      7.141062    9.197104  \n",
       "min      1.730000    5.000000  \n",
       "25%      6.950000   17.025000  \n",
       "50%     11.360000   21.200000  \n",
       "75%     16.955000   25.000000  \n",
       "max     37.970000   50.000000  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Brand Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitosis</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.990000e+02</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.071704e+06</td>\n",
       "      <td>4.417740</td>\n",
       "      <td>3.134478</td>\n",
       "      <td>3.207439</td>\n",
       "      <td>2.806867</td>\n",
       "      <td>3.216023</td>\n",
       "      <td>3.437768</td>\n",
       "      <td>2.866953</td>\n",
       "      <td>1.589413</td>\n",
       "      <td>2.689557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.170957e+05</td>\n",
       "      <td>2.815741</td>\n",
       "      <td>3.051459</td>\n",
       "      <td>2.971913</td>\n",
       "      <td>2.855379</td>\n",
       "      <td>2.214300</td>\n",
       "      <td>2.438364</td>\n",
       "      <td>3.053634</td>\n",
       "      <td>1.715078</td>\n",
       "      <td>0.951273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.163400e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.706885e+05</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.171710e+06</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.238298e+06</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.345435e+07</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID  Clump Thickness  Uniformity of Cell Size  \\\n",
       "count  6.990000e+02       699.000000               699.000000   \n",
       "mean   1.071704e+06         4.417740                 3.134478   \n",
       "std    6.170957e+05         2.815741                 3.051459   \n",
       "min    6.163400e+04         1.000000                 1.000000   \n",
       "25%    8.706885e+05         2.000000                 1.000000   \n",
       "50%    1.171710e+06         4.000000                 1.000000   \n",
       "75%    1.238298e+06         6.000000                 5.000000   \n",
       "max    1.345435e+07        10.000000                10.000000   \n",
       "\n",
       "       Uniformity of Cell Shape  Marginal Adhesion  \\\n",
       "count                699.000000         699.000000   \n",
       "mean                   3.207439           2.806867   \n",
       "std                    2.971913           2.855379   \n",
       "min                    1.000000           1.000000   \n",
       "25%                    1.000000           1.000000   \n",
       "50%                    1.000000           1.000000   \n",
       "75%                    5.000000           4.000000   \n",
       "max                   10.000000          10.000000   \n",
       "\n",
       "       Single Epithelial Cell Size  Brand Chromatin  Normal Nucleoli  \\\n",
       "count                   699.000000       699.000000       699.000000   \n",
       "mean                      3.216023         3.437768         2.866953   \n",
       "std                       2.214300         2.438364         3.053634   \n",
       "min                       1.000000         1.000000         1.000000   \n",
       "25%                       2.000000         2.000000         1.000000   \n",
       "50%                       2.000000         3.000000         1.000000   \n",
       "75%                       4.000000         5.000000         4.000000   \n",
       "max                      10.000000        10.000000        10.000000   \n",
       "\n",
       "          Mitosis       Class  \n",
       "count  699.000000  699.000000  \n",
       "mean     1.589413    2.689557  \n",
       "std      1.715078    0.951273  \n",
       "min      1.000000    2.000000  \n",
       "25%      1.000000    2.000000  \n",
       "50%      1.000000    2.000000  \n",
       "75%      1.000000    4.000000  \n",
       "max     10.000000    4.000000  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data sets for cross-validation \n",
    "\n",
    "Simple training and test sets with 70% of the day and 30% of the data respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split as split\n",
    "boston_train, boston_test = split(boston, test_size = .30)\n",
    "cancer_train, cancer_test = split(cancer, test_size = .30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = ['crim', 'zn', 'indus', 'chas', 'nox', 'rm', \n",
    "            'age', 'dis', 'rad', 'tax', 'ptratio', 'black', 'lstat']\n",
    "target = 'medv'\n",
    "predictor_data = boston_train[features].values\n",
    "median_price = boston_train[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 0.738997625457\n",
      "\n",
      "\n",
      "intercept: 40.8968130631\n",
      "crim: -0.0539408946798\n",
      "zn: 0.0493699460351\n",
      "indus: 0.0507447173769\n",
      "chas: 3.97291325389\n",
      "nox: -15.5988827731\n",
      "rm: 3.03820627625\n",
      "age: 0.00141154582491\n",
      "dis: -1.29957330381\n",
      "rad: 0.30438214487\n",
      "tax: -0.0133889512067\n",
      "ptratio: -1.04001863779\n",
      "black: 0.0105704606479\n",
      "lstat: -0.583174491065\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnoAAAFwCAYAAAAv2db3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRaAHAAAQKAI9AACAQP1/+cmXi2p0LeUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1193c3d90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(predictor_data, median_price)\n",
    "\n",
    "\n",
    "y_hat = linear_regression.predict(predictor_data)\n",
    "resids = y_hat - median_price\n",
    "plt.figure(figsize = (10.5, 6))\n",
    "plt.scatter(range(len(median_price)), resids)\n",
    "\n",
    "\n",
    "print \"R2 \" + str(linear_regression.score(predictor_data, median_price)) + \"\\n\\n\"\n",
    "coefficients = linear_regression.coef_.tolist()\n",
    "print \"intercept: \" + str(linear_regression.intercept_)\n",
    "for predictor in range(len(features)):\n",
    "    print features[predictor] + \": \" + str(coefficients[predictor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first predictions for prices are: \n",
      "\t35.8911585503\n",
      "\t27.5575645252\n",
      "\t33.1818723397\n",
      "\t22.1451647068\n",
      "\t12.3842951453\n",
      "\t12.152815309\n",
      "\t20.309225648\n",
      "\t16.7330372915\n",
      "\t31.9338756575\n",
      "\t30.5099771081\n",
      "\n",
      "And the R-Squared value for the unseen data is: 0.723654914036\n"
     ]
    }
   ],
   "source": [
    "testing_data = boston_test[features].values\n",
    "testing_targets = boston_test[target].values\n",
    "new_predictions = linear_regression.predict(predictor_data)\n",
    "print \"The first predictions for prices are: \"\n",
    "for i in range(10):\n",
    "    print \"\\t\" + str(new_predictions[i])\n",
    "    \n",
    "#print linear_regression.predict(testing_data)[:10]\n",
    "R2 = linear_regression.score(testing_data, testing_targets)\n",
    "print \"\\nAnd the R-Squared value for the unseen data is: \" + str(R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Trees \n",
    "\n",
    "\"Prediction trees use the tree to represent the recursive partition. Each of the terminal nodes, or leaves, of the tree represents a cell of the partition, and has attached to it a simple model which applies in that cell only. A point x belongs to a leaf if x falls in the corresponding cell of the partition.\"--Cosma Shalizi \n",
    "\n",
    "* Data \"splits\" to make the predictions\n",
    "* Greedy algorithm: makes best choice at each stage; doesn't look far ahead\n",
    "* May miss a really good split down the line \n",
    "* Bagging: Combining similar trees and averaging outcome\n",
    "* Random Forest: Combining vastly different trees and average outcome\n",
    "    * Does this by hiding data from the trees at different time so optimum's look different\n",
    "    * Leo Breiman: Can't Overfit \n",
    "\n",
    "<img src=\"https://camo.githubusercontent.com/4dad481e246c73548fb37cb3dc26ea106a2494dc/687474703a2f2f65636f6c6f67792e6d73752e6d6f6e74616e612e6564752f6c61626473762f522f6c6162732f6c6162362f64656d6f5f332e706e67\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 for the Tree Regression is 0.990922323843\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree = DecisionTreeRegressor(max_depth = 10)\n",
    "tree.fit(predictor_data, median_price)\n",
    "from sklearn.metrics import r2_score\n",
    "print \"The R2 for the Tree Regression is \" + str(r2_score(median_price, tree.predict(predictor_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 for the new data is 0.839568046061\n"
     ]
    }
   ],
   "source": [
    "new_preds = tree.predict(testing_data)\n",
    "print \"The R2 for the new data is \" + str(r2_score(testing_targets, new_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification & Logistic Regression \n",
    "\n",
    "### Logistic Regression \n",
    "* Feed linear regression into the sigmoid function $S(t) = \\frac{1}{1 + e^{-t}}$ where $t$ is the linear regression\n",
    "* Used for binary classification\n",
    "    * $ \\le .5 \\Rightarrow$ class 0\n",
    "    * $ > .5 \\Rightarrow$ class 1\n",
    "* Need new metrics since $R^2$ doesn't make sense here \n",
    "    * Log-Loss if you predict probabilities (big for Kaggle)\n",
    "    * Accuracy score that looks at the proportion of the correctly classified \n",
    "\n",
    "<img src=\"sigmoid.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Brand Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitosis</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1017122</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1018099</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1018561</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1033078</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1033078</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1035283</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1036172</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1041801</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1043999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1044572</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1047630</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1048672</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1049815</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1050670</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1050718</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  Clump Thickness  Uniformity of Cell Size  \\\n",
       "0   1000025                5                        1   \n",
       "1   1002945                5                        4   \n",
       "2   1015425                3                        1   \n",
       "3   1016277                6                        8   \n",
       "4   1017023                4                        1   \n",
       "5   1017122                8                       10   \n",
       "6   1018099                1                        1   \n",
       "7   1018561                2                        1   \n",
       "8   1033078                2                        1   \n",
       "9   1033078                4                        2   \n",
       "10  1035283                1                        1   \n",
       "11  1036172                2                        1   \n",
       "12  1041801                5                        3   \n",
       "13  1043999                1                        1   \n",
       "14  1044572                8                        7   \n",
       "15  1047630                7                        4   \n",
       "16  1048672                4                        1   \n",
       "17  1049815                4                        1   \n",
       "18  1050670               10                        7   \n",
       "19  1050718                6                        1   \n",
       "\n",
       "    Uniformity of Cell Shape  Marginal Adhesion  Single Epithelial Cell Size  \\\n",
       "0                          1                  1                            2   \n",
       "1                          4                  5                            7   \n",
       "2                          1                  1                            2   \n",
       "3                          8                  1                            3   \n",
       "4                          1                  3                            2   \n",
       "5                         10                  8                            7   \n",
       "6                          1                  1                            2   \n",
       "7                          2                  1                            2   \n",
       "8                          1                  1                            2   \n",
       "9                          1                  1                            2   \n",
       "10                         1                  1                            1   \n",
       "11                         1                  1                            2   \n",
       "12                         3                  3                            2   \n",
       "13                         1                  1                            2   \n",
       "14                         5                 10                            7   \n",
       "15                         6                  4                            6   \n",
       "16                         1                  1                            2   \n",
       "17                         1                  1                            2   \n",
       "18                         7                  6                            4   \n",
       "19                         1                  1                            2   \n",
       "\n",
       "   Bare Nuclei  Brand Chromatin  Normal Nucleoli  Mitosis  Class  \n",
       "0            1                3                1        1      2  \n",
       "1           10                3                2        1      2  \n",
       "2            2                3                1        1      2  \n",
       "3            4                3                7        1      2  \n",
       "4            1                3                1        1      2  \n",
       "5           10                9                7        1      4  \n",
       "6           10                3                1        1      2  \n",
       "7            1                3                1        1      2  \n",
       "8            1                1                1        5      2  \n",
       "9            1                2                1        1      2  \n",
       "10           1                3                1        1      2  \n",
       "11           1                2                1        1      2  \n",
       "12           3                4                4        1      4  \n",
       "13           3                3                1        1      2  \n",
       "14           9                5                5        4      4  \n",
       "15           1                4                3        1      4  \n",
       "16           1                2                1        1      2  \n",
       "17           1                3                1        1      2  \n",
       "18          10                4                1        2      4  \n",
       "19           1                3                1        1      2  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Brand Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitosis</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.990000e+02</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.071704e+06</td>\n",
       "      <td>4.417740</td>\n",
       "      <td>3.134478</td>\n",
       "      <td>3.207439</td>\n",
       "      <td>2.806867</td>\n",
       "      <td>3.216023</td>\n",
       "      <td>3.437768</td>\n",
       "      <td>2.866953</td>\n",
       "      <td>1.589413</td>\n",
       "      <td>2.689557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.170957e+05</td>\n",
       "      <td>2.815741</td>\n",
       "      <td>3.051459</td>\n",
       "      <td>2.971913</td>\n",
       "      <td>2.855379</td>\n",
       "      <td>2.214300</td>\n",
       "      <td>2.438364</td>\n",
       "      <td>3.053634</td>\n",
       "      <td>1.715078</td>\n",
       "      <td>0.951273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.163400e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.706885e+05</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.171710e+06</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.238298e+06</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.345435e+07</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID  Clump Thickness  Uniformity of Cell Size  \\\n",
       "count  6.990000e+02       699.000000               699.000000   \n",
       "mean   1.071704e+06         4.417740                 3.134478   \n",
       "std    6.170957e+05         2.815741                 3.051459   \n",
       "min    6.163400e+04         1.000000                 1.000000   \n",
       "25%    8.706885e+05         2.000000                 1.000000   \n",
       "50%    1.171710e+06         4.000000                 1.000000   \n",
       "75%    1.238298e+06         6.000000                 5.000000   \n",
       "max    1.345435e+07        10.000000                10.000000   \n",
       "\n",
       "       Uniformity of Cell Shape  Marginal Adhesion  \\\n",
       "count                699.000000         699.000000   \n",
       "mean                   3.207439           2.806867   \n",
       "std                    2.971913           2.855379   \n",
       "min                    1.000000           1.000000   \n",
       "25%                    1.000000           1.000000   \n",
       "50%                    1.000000           1.000000   \n",
       "75%                    5.000000           4.000000   \n",
       "max                   10.000000          10.000000   \n",
       "\n",
       "       Single Epithelial Cell Size  Brand Chromatin  Normal Nucleoli  \\\n",
       "count                   699.000000       699.000000       699.000000   \n",
       "mean                      3.216023         3.437768         2.866953   \n",
       "std                       2.214300         2.438364         3.053634   \n",
       "min                       1.000000         1.000000         1.000000   \n",
       "25%                       2.000000         2.000000         1.000000   \n",
       "50%                       2.000000         3.000000         1.000000   \n",
       "75%                       4.000000         5.000000         4.000000   \n",
       "max                      10.000000        10.000000        10.000000   \n",
       "\n",
       "          Mitosis       Class  \n",
       "count  699.000000  699.000000  \n",
       "mean     1.589413    2.689557  \n",
       "std      1.715078    0.951273  \n",
       "min      1.000000    2.000000  \n",
       "25%      1.000000    2.000000  \n",
       "50%      1.000000    2.000000  \n",
       "75%      1.000000    4.000000  \n",
       "max     10.000000    4.000000  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['Clump Thickness', 'Uniformity of Cell Shape', 'Marginal Adhesion', \n",
    "            'Single Epithelial Cell Size', 'Brand Chromatin', 'Normal Nucleoli', 'Mitosis']\n",
    "target = 'Class'\n",
    "predictor_data = cancer_train[features].values\n",
    "cell_class = cancer_train[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model predicts 96.5235173824% of the cells accurately\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(predictor_data, cell_class)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print \"The model predicts \" + str(accuracy_score(cell_class, logistic_regression.predict(predictor_data))*100) + \"% of the cells accurately\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_data = cancer_test[features].values\n",
    "validation_target = cancer_test[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Also predicts 95.7142857143% of new observations\n"
     ]
    }
   ],
   "source": [
    "new_preds = logistic_regression.predict(validation_data)\n",
    "print \"Also predicts \" + str(accuracy_score(validation_target, new_preds)*100) + \"% of new observations\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "New Belief = Old Belief $\\times$ Likelihood of Evidence / Evidence $\\leftarrow$ Bayes' Rule\n",
    "\n",
    "* \"Naive\" Because the algorithm assumes all predictors are conditionally independent of other predictors, which is dumb\n",
    "* Uses the top half of Bayes rule and compares the two classes; Selects the larger value for classes\n",
    "* Probabilities tend towards 0 and 1 \n",
    "    * Principle components vote more than once, skewing the results\n",
    "* Used for spam classifiers \n",
    "* Converges into Logistic Regression as the predictors become more and more independent\n",
    "* Gaussian Naive Bayes assumes underlying probabilities are normally distributed \n",
    "* You can start with \"priors\" and weight for data that's skewed towards one classifier or the other "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicts 96.1904761905% of unseen observations\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gaussian_NB = GaussianNB()\n",
    "old_preds = gaussian_NB.fit(cancer_train[features].values, cell_class)\n",
    "new_preds = gaussian_NB.predict(validation_data)\n",
    "print \"Predicts \" + str(accuracy_score(validation_target, new_preds) * 100) + \"% of unseen observations\"\n",
    "\n",
    "#print accuracy_score(cell_class, old_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
